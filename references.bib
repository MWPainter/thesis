

%%%%%
% THTS stuff
%%%%%

@inproceedings{thts,
  title={Trial-based heuristic tree search for finite horizon MDPs},
  author={Keller, Thomas and Helmert, Malte},
  booktitle={Proceedings of the International Conference on Automated Planning and Scheduling},
  volume={23},
  pages={135--143},
  year={2013}
}

@software{thtspp,
	author = {Painter, Michael},
	title = {{THTS++}},
  type = {Software},
	note = {Available at \url{https://github.com/MWPainter/thts-plus-plus}},
	url = {https://github.com/MWPainter/thts-plus-plus},
	version = {0.0},
  year={2025}
}

martinez2014bayesopt
@techreport{bayesopt,
  title={Bayesopt: A bayesian optimization library for nonlinear optimization, experimental design and bandits},
  author={Martinez-Cantin, Ruben},
  year={2014}
}

%%%%%
% RL
%%%%%

%sutton2018reinforcement
% rl book
@article{sutton,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S},
  journal={A Bradford Book},
  year={2018}
}

%natarajan2022planning
%planning with mdps
@book{kolobov,
  title={Planning with Markov decision processes: An AI perspective},
  author={Natarajan, Mausam and Kolobov, Andrey},
  year={2022},
  publisher={Springer Nature}
}

% Bellman:DynamicProgramming
% value iteration
@book{dp,
  author = {Bellman, Richard},
  isbn = {9780486428093},
  keywords = {book dynamic programming},
  publisher = {Dover Publications},
  timestamp = {2011-08-18T09:10:27.000+0200},
  title = {{Dynamic Programming}},
  year = 1957
}

%%%%%
% MCTS stuff
%%%%%

% browne2012survey
% survey on mcts
@article{mcts_survey,
  title={A survey of monte carlo tree search methods},
  author={Browne, Cameron B and Powley, Edward and Whitehouse, Daniel and Lucas, Simon M and Cowling, Peter I and Rohlfshagen, Philipp and Tavener, Stephen and Perez, Diego and Samothrakis, Spyridon and Colton, Simon},
  journal={IEEE Transactions on Computational Intelligence and AI in games},
  volume={4},
  number={1},
  pages={1--43},
  year={2012},
  publisher={IEEE}
}

% kocsis2006bandit
% uct - original
@inproceedings{uct,
  title={Bandit based monte-carlo planning},
  author={Kocsis, Levente and Szepesv{\'a}ri, Csaba},
  booktitle={European conference on machine learning},
  pages={282--293},
  year={2006},
  organization={Springer}
}

% kocsis2006improved
% uct - long - with proofs
@article{uct_long,
  title={Improved monte-carlo search},
  author={Kocsis, Levente and Szepesv{\'a}ri, Csaba and Willemson, Jan},
  journal={Univ. Tartu, Estonia, Tech. Rep},
  volume={1},
  pages={1--22},
  year={2006}
}

% xiao2019maximum
% METNS
@article{ments,
  title={Maximum entropy monte-carlo planning},
  author={Xiao, Chenjun and Huang, Ruitong and Mei, Jincheng and Schuurmans, Dale and M{\"u}ller, Martin},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

% gelly2011monte
% rave
@article{rave,
  title={Monte-Carlo tree search and rapid action value estimation in computer Go},
  author={Gelly, Sylvain and Silver, David},
  journal={Artificial Intelligence},
  volume={175},
  number={11},
  pages={1856--1875},
  year={2011},
  publisher={Elsevier}
}

% silver2016mastering
% alpha go
@article{alpha_go,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

%silver2017mastering
%alpha go zero
@article{alpha_go_zero,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

%silver2018general
%alpha zero
@article{alpha_zero,
  title={A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={Science},
  volume={362},
  number={6419},
  pages={1140--1144},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

% wu2019accelerating
% kata go
@article{katago,
  title={Accelerating self-play learning in go},
  author={Wu, David J},
  journal={arXiv preprint arXiv:1902.10565},
  year={2019}
}

%moerland2018a0c
%a0c
@article{a0c,
  title={A0c: Alpha zero in continuous action space},
  author={Moerland, Thomas M and Broekens, Joost and Plaat, Aske and Jonker, Catholijn M},
  journal={arXiv preprint arXiv:1805.09613},
  year={2018}
}

%gelly2007combining
% Go - rave
@inproceedings{rave,
  title={Combining online and offline knowledge in UCT},
  author={Gelly, Sylvain and Silver, David},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={273--280},
  year={2007}
}

% keller2012prost
% PROST - variable bias param
% prost planner - eg of using rollout
@inproceedings{prost,
  title={PROST: Probabilistic planning based on UCT},
  author={Keller, Thomas and Eyerich, Patrick},
  booktitle={Proceedings of the International Conference on Automated Planning and Scheduling},
  volume={22},
  pages={119--127},
  year={2012}
}

% coquelin2007bandit
% D-Chain
@article{dchain,
  title={Bandit algorithms for tree search},
  author={Coquelin, Pierre-Arnaud and Munos, R{\'e}mi},
  journal={arXiv preprint cs/0703062},
  year={2007}
}

% karnin2013almost
% hmcts
@inproceedings{hmcts,
  title={Almost optimal exploration in multi-armed bandits},
  author={Karnin, Zohar and Koren, Tomer and Somekh, Oren},
  booktitle={International conference on machine learning},
  pages={1238--1246},
  year={2013},
  organization={PMLR}
}

% dam2021convex
% rents and tents
@inproceedings{rentsmytents,
  title={Convex regularization in monte-carlo tree search},
  author={Dam, Tuan Q and Dâ€™Eramo, Carlo and Peters, Jan and Pajarinen, Joni},
  booktitle={International Conference on Machine Learning},
  pages={2365--2375},
  year={2021},
  organization={PMLR}
}

% sailing env evaluator
@article{peret2004line,
  title={On-line search for solving Markov decision processes via heuristic sampling},
  author={P{\'e}ret, Laurent and Garcia, Fr{\'e}d{\'e}rick},
  journal={learning},
  volume={16},
  pages={2},
  year={2004}
}

% sailing env evaluator + simple regret method 
@inproceedings{tolpin2012mcts,
  title={MCTS based on simple regret},
  author={Tolpin, David and Shimony, Solomon},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={26},
  number={1},
  pages={570--576},
  year={2012}
}

% brue1
% simple regret
% sailing env enjoyer
@article{brue1,
  title={Monte-Carlo planning: Theoretically fast convergence meets practical efficiency},
  author={Feldman, Zohar and Domshlak, Carmel},
  journal={arXiv preprint arXiv:1309.6828},
  year={2013}
}

@inproceedings{gelly2007combining,
  title={Combining online and offline knowledge in UCT},
  author={Gelly, Sylvain and Silver, David},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={273--280},
  year={2007}
}

% auger2013continuous
% polynomial uct
@inproceedings{poly_uct,
  title={Continuous upper confidence trees with polynomial exploration--consistency},
  author={Auger, David and Couetoux, Adrien and Teytaud, Olivier},
  booktitle={Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2013, Prague, Czech Republic, September 23-27, 2013, Proceedings, Part I 13},
  pages={194--209},
  year={2013},
  organization={Springer}
}

% rosin2011multi
% prioritised ucb
@article{prio_ucb,
  title={Multi-armed bandits with episode context},
  author={Rosin, Christopher D},
  journal={Annals of Mathematics and Artificial Intelligence},
  volume={61},
  number={3},
  pages={203--230},
  year={2011},
  publisher={Springer}
}

%%%%%
% MORL stuff
%%%%%

% survey
@article{morl_survey,
  title={A practical guide to multi-objective reinforcement learning and planning},
  author={Hayes, Conor F and R{\u{a}}dulescu, Roxana and Bargiacchi, Eugenio and K{\"a}llstr{\"o}m, Johan and Macfarlane, Matthew and Reymond, Mathieu and Verstraeten, Timothy and Zintgraf, Luisa M and Dazeley, Richard and Heintz, Fredrik and others},
  journal={Autonomous Agents and Multi-Agent Systems},
  volume={36},
  number={1},
  pages={26},
  year={2022},
  publisher={Springer}
}

%barrett2008learning,
% convex hull value iter
@inproceedings{chvi,
  title={Learning all optimal policies with multiple criteria},
  author={Barrett, Leon and Narayanan, Srini},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={41--47},
  year={2008}
}

% roijers2015computing
% linear prog for convex prune
@article{cccs,
  title={Computing convex coverage sets for faster multi-objective coordination},
  author={Roijers, Diederik Marijn and Whiteson, Shimon and Oliehoek, Frans A},
  journal={Journal of Artificial Intelligence Research},
  volume={52},
  pages={399--443},
  year={2015}
}

%%%%%
% Max Entr/Entropy Exploration RL stuff
%%%%%

%haarnoja2017reinforcement
% popularised Max Ent for policy gradient
@inproceedings{deep_energy_policies,
  title={Reinforcement learning with deep energy-based policies},
  author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1352--1361},
  year={2017},
  organization={PMLR}
}

%mnih2016asynchronous,
% uses entropy for exploration too
@inproceedings{a3c,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016},
  organization={PmLR}
}

%williams1991function
% OG policy gradients (REINFORCE), also have variant using entropy
@article{reinforce_ment,
  title={Function optimization using connectionist reinforcement learning algorithms},
  author={Williams, Ronald J and Peng, Jing},
  journal={Connection Science},
  volume={3},
  number={3},
  pages={241--268},
  year={1991},
  publisher={Taylor \& Francis}
}

%schulman2017proximal
% PPO uses entropy for exploration too
@article{ppo,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}


%%%%%
% POMDPs
%%%%%

%silver2010monte
%pomcp
@article{pomcp,
  title={Monte-Carlo planning in large POMDPs},
  author={Silver, David and Veness, Joel},
  journal={Advances in neural information processing systems},
  volume={23},
  year={2010}
}

%%%%%
% MABs
%%%%%

%robbins1952some
%mab original
@article{mab_og,
  title={Some aspects of the sequential design of experiments},
  author={Robbins, Herbert},
  year={1952}
}

%lai1985asymptotically
% mab lower bound
@article{mab_lower_bound,
  title={Asymptotically efficient adaptive allocation rules},
  author={Lai, Tze Leung and Robbins, Herbert},
  journal={Advances in applied mathematics},
  volume={6},
  number={1},
  pages={4--22},
  year={1985},
  publisher={Academic Press}
}

%auer2002finite
$ucb
@misc{ucb,
  title={Finite-time Analysis of the Multiarmed Bandit Problem},
  author={Auer, P},
  year={2002},
  publisher={Kluwer Academic Publishers}
}

%bubeck2009pure
% exploring bandits
@inproceedings{exploring_bandit,
  title={Pure exploration in multi-armed bandits problems},
  author={Bubeck, S{\'e}bastien and Munos, R{\'e}mi and Stoltz, Gilles},
  booktitle={Algorithmic Learning Theory: 20th International Conference, ALT 2009, Porto, Portugal, October 3-5, 2009. Proceedings 20},
  pages={23--37},
  year={2009},
  organization={Springer}
}

%kleinberg2008multi
%zooming short
@inproceedings{cz,
  title={Multi-armed bandits in metric spaces},
  author={Kleinberg, Robert and Slivkins, Aleksandrs and Upfal, Eli},
  booktitle={Proceedings of the fortieth annual ACM symposium on Theory of computing},
  pages={681--690},
  year={2008}
}

%slivkins2011contextual
%zooming long
@inproceedings{cz_long,
  title={Contextual bandits with similarity information},
  author={Slivkins, Aleksandrs},
  booktitle={Proceedings of the 24th annual Conference On Learning Theory},
  pages={679--702},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

%%%%%
% Misc - usually used in a passing comment, things that aren't super critical to thesis
%%%%%

%shannon1948mathematical
% shannon entropy
@article{entropy,
  title={A mathematical theory of communication},
  author={Shannon, Claude Elwood},
  journal={The Bell system technical journal},
  volume={27},
  number={3},
  pages={379--423},
  year={1948},
  publisher={Nokia Bell Labs}
}

% barto1995learning
% rtdp
@article{rtdp,
  title={Learning to act using real-time dynamic programming},
  author={Barto, Andrew G and Bradtke, Steven J and Singh, Satinder P},
  journal={Artificial intelligence},
  volume={72},
  number={1-2},
  pages={81--138},
  year={1995},
  publisher={Elsevier}
}

%hansen2001lao
%LAO*
@article{lao_star,
  title={LAO*: A heuristic search algorithm that finds solutions with loops},
  author={Hansen, Eric A and Zilberstein, Shlomo},
  journal={Artificial Intelligence},
  volume={129},
  number={1-2},
  pages={35--62},
  year={2001},
  publisher={Elsevier}
}

%cazenave2009monte
% example of using a rollout policy - bus planning
@inproceedings{bus,
  title={Monte-Carlo bus regulation},
  author={Cazenave, Tristan and Balbo, Flavien and Pinson, Suzanne and others},
  booktitle={12th international IEEE conference on intelligent transportation systems},
  volume={340345},
  year={2009}
}

%abramson1990expected
% og notion of using a MC estimate from random policy to eval states
@article{rand_mc_est_orig,
  title={Expected-outcome: A general model of static evaluation},
  author={Abramson, Bruce},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={12},
  number={2},
  pages={182--193},
  year={1990},
  publisher={IEEE}
}

%walker1977efficient
%alias original
@article{alias_method_one,
  title={An efficient method for generating discrete random variables with general distributions},
  author={Walker, Alastair J},
  journal={ACM Transactions on Mathematical Software (TOMS)},
  volume={3},
  number={3},
  pages={253--256},
  year={1977},
  publisher={ACM New York, NY, USA}
}

%vose1991linear
%alias correctness
@article{alias_method_two,
  title={A linear algorithm for generating random numbers with a given distribution},
  author={Vose, Michael D},
  journal={IEEE Transactions on software engineering},
  volume={17},
  number={9},
  pages={972--975},
  year={1991},
  publisher={Citeseer}
}
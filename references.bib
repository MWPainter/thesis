

%%%%%
% THTS stuff
%%%%%

@inproceedings{thts,
  title={Trial-based heuristic tree search for finite horizon MDPs},
  author={Keller, Thomas and Helmert, Malte},
  booktitle={Proceedings of the International Conference on Automated Planning and Scheduling},
  volume={23},
  pages={135--143},
  year={2013}
}

@software{thtspp,
	author = {Painter, Michael},
	title = {{THTS++}},
	url = {https://github.com/MWPainter/thts-plus-plus},
	version = {0.0}
}

%%%%%
% MORL stuff
%%%%%

% survey
@article{morl_survey,
  title={A practical guide to multi-objective reinforcement learning and planning},
  author={Hayes, Conor F and R{\u{a}}dulescu, Roxana and Bargiacchi, Eugenio and K{\"a}llstr{\"o}m, Johan and Macfarlane, Matthew and Reymond, Mathieu and Verstraeten, Timothy and Zintgraf, Luisa M and Dazeley, Richard and Heintz, Fredrik and others},
  journal={Autonomous Agents and Multi-Agent Systems},
  volume={36},
  number={1},
  pages={26},
  year={2022},
  publisher={Springer}
}

%barrett2008learning,
% convex hull value iter
@inproceedings{chvi,
  title={Learning all optimal policies with multiple criteria},
  author={Barrett, Leon and Narayanan, Srini},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={41--47},
  year={2008}
}

%%%%%
% Max Entr RL stuff
%%%%%

%haarnoja2017reinforcement
% as far as I'm concerned, the original max entropy RL paper
@inproceedings{deep_energy_policies,
  title={Reinforcement learning with deep energy-based policies},
  author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1352--1361},
  year={2017},
  organization={PMLR}
}

%%%%%
% Misc
%%%%%

%shannon1948mathematical
@article{entropy,
  title={A mathematical theory of communication},
  author={Shannon, Claude Elwood},
  journal={The Bell system technical journal},
  volume={27},
  number={3},
  pages={379--423},
  year={1948},
  publisher={Nokia Bell Labs}
}
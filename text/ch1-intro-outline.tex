% \begin{savequote}[8cm]
% \textlatin{Neque porro quisquam est qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit...}

% There is no one who loves pain itself, who seeks after it and wants to have it, simply because it is pain...
%   \qauthor{--- Cicero's \textit{de Finibus Bonorum et Malorum}}
% \end{savequote}

\chapter{\label{ch:1-intro}Introduction} 

    \minitoc

    \todo{chapter structure (i.e. in the introduction section I give some background in the field(s), cover the main 
    contributions of this thesis, etc, etc).}

\section{Overview}
\label{sec:1-1-overview}

    \todo{list}
    \begin{itemize}
        \item Give some context around MCTS (and talk about exploration and exploitation), and why we might use it
        \begin{itemize}
            \item Larger scale than tabular methods
            \item Can do probability and theory stuff (and some explainability, by looking at stats in the tree the agent used)
            \item Can use tree search with neural networks to get some of the above (and use for neural network training as in alpha zero)
        \end{itemize}
        \item Argument from DENTS paper for exploration > exploitation (in context of planning in a simulator)
        \item Give high level overview of Multi-Objective RL, and why it can be useful
        \item Give an idea of how my work fits into MCTS and MORL as a whole
        \item Discuss research questions/issues with current literature (i.e. introduce some of the ideas from contributions section below)
    \end{itemize}

\section{Contributions}
\label{sec:1-2-contributions}

    \todo{Inline acronyms used, or make sure that they're defined before hand}

    Throughout this thesis, we will consider the following questions related to Monte Carlo Tree Search and Multi-Objective Reinforcement Learning:
    \begin{enumerate}[start=1, label={\textbf{Q\arabic* -}}]
        % \item \hypertarget{q1}{\textbf{Time-Limited Planning:}} How do we ensure that MCTS algorithms make good decisions when limited planning time is available?
        \item \hypertarget{q1}{\textbf{Exploration:}} When planning in a simulator with limited time, how can MCTS algorithms best explore to make good decisions?
        
        \begin{enumerate}[start=1, label={\textbf{Q1.\arabic* -}}]
            \item \hypertarget{q11}{\textbf{Entropy:}} Entropy is often used as an exploration objective in RL, but can it be used soundly in MCTS?
            \item \hypertarget{q12}{\textbf{Multi-Objective Exploration:}} How can Multi-Objective MCTS methods explore to find optimal actions for different objectives? 
        \end{enumerate}

        \item \hypertarget{q2}{\textbf{Scalability:}} How can the scalability of (multi-objective) MCTS methods be improved?

        \begin{enumerate}[start=1, label={\textbf{Q2.\arabic* -}}]
            \item \hypertarget{q21}{\textbf{Complexity:}} MCTS algorithms typically run in $O(nAH)$, but are there algorithms that can improve upon this?
            \item \hypertarget{q22}{\textbf{Multi-Objective Scalability:}} With respect to the size of environments, how scalable are Multi-Objective MCTS methods?
            \item \hypertarget{q23}{\textbf{Curse of Dimensionality:}} With respect to the number of objectives, to what extent do Multi-Objective MCTS methods suffer from the curse of dimensionality?
        \end{enumerate}


        \item \hypertarget{q3}{\textbf{Evaluation:}} How can we best evaluate a search tree produced by a Monte Carlo Tree Search algorithm?
        
        \begin{enumerate}[start=1, label={\textbf{Q3.\arabic* -}}]
            \item \hypertarget{q31}{\textbf{Tree Policies:}} Does it suffice to extract a policy from a single search tree for evaluation? \todo{going to have to run some extra experiments for that, but I probably should do that for completeness anyway}
            \item \hypertarget{q32}{\textbf{Multi-Objective Evaluation:}} Can we apply methods from the MORL literature to theoretically and empirically evaluate Multi-Objective MCTS?
        \end{enumerate}
    \end{enumerate}

    \todo{some words about how below is the contributions we're making in this thesis and expand these bullets a bit more}
    \begin{itemize}
        \item Max Entropy can be misaligned with reward maximisation (\entropyq)
        \item Boltzmann Search Policies - BTS and DENTS (\entropyq, and with extra results \treepolicyq)
        \item Use the alias method to make faster algorithms (\complexityq)
        \item Simple regret (\exploreq)
        \item Use of contexts in THTS to make consistent decisions in each trial (\contextq)
        \item Contextual regret introduced in CHMCTS (\moscalabilityq, \moevalq)
        \item Contextual Zooming and CHMCTS (designed for \contextq, runtimes cover \dimq, results \moevalq)
        \item Simplex maps (\contextq, \moscalabilityq, \dimq)
        \item Contextual Simple Regret (\moevalq)
    \end{itemize}

    \hide{\todo{Would like to do the comparing different types of eval, even if not listing it as a research question 
    (compare giving it X seconds per decision and evaluating that policy (SLOW), and comparing policy extracted from 
    the tree)}}

    \hide{\todo{can make an argument that the best bound achieved by theory is given by letting temperature go to max. Which is consistent with the exploring bandits results}}



\section{Structure of Thesis}
\label{sec:1-3-thesis-structure}

    \todo{a paragraph with a couple lines to a paragraph about each chapter. This is the high level overview/intro to 
    the thesis paragraph. I.e. this section is ``this is the story of my thesis in a page or two''}

\section{Publications}
\label{sec:1-4-publications}

    \todo{update final publication when submit}

    The work covered in this thesis also appears in the following publications:
    \begin{itemize}
        \item Painter, M; Lacerda, B; and Hawes, N. ``Convex Hull Monte-Carlo Tree-Search." In \textit{Proceedings of the international conference on automated planning and scheduling. Vol. 30. 2020}, ICAPS, 2020, (see Appendix~\ref{app:p1-chmcts}).
        \item Painter, M; Baioumy, M; Hawes, N; and Lacerda, B.  ``Monte Carlo Tree Search With Boltzmann Exploration." In \textit{Advances in Neural Information Processing Systems, 36, 2023}, NeurIPS, 2023, (see Appendix~\ref{app:p2-dents}).
        \item Painter, M; Hawes, N; and Lacerda, B. ``Simplex Maps for Multi-Objective Monte Carlo Tree Search." In \textit{TODO}, \textbf{Under Review at conf\_name}, (see Appendix~\ref{app:p3-simplexmaps}).
    \end{itemize}